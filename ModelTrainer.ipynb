{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os as os\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import TFNNModels as NNM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good_inp = pd.read_csv('DataFiles\\Good_Input_Data.csv')  # import data\n",
    "df_good_target = pd.read_csv('DataFiles\\Good_Target_Data.csv')  # import data\n",
    "\n",
    "inp = np.asarray(df_good_inp)\n",
    "tar_vm1x = np.asarray(df_good_target['0'])\n",
    "tar_vm1y = np.asarray(df_good_target['1'])\n",
    "tar_vm2x = np.asarray(df_good_target['2'])\n",
    "tar_vm2y = np.asarray(df_good_target['3'])\n",
    "\n",
    "\n",
    "# 0:24004  60% train\n",
    "# 24005:(24005+8000) val\n",
    "# (24005+8001) : 40008 test\n",
    "\n",
    "# training set \n",
    "train_input = inp[0:24004]\n",
    "train_target_vm1x = tar_vm1x[0:24004]\n",
    "train_target_vm1y = tar_vm1y[0:24004]\n",
    "train_target_vm2x = tar_vm2x[0:24004]\n",
    "train_target_vm2y = tar_vm2y[0:24004]\n",
    "\n",
    "# validation set\n",
    "val_input = inp[24005:(24005+8000)]\n",
    "val_target_vm1x = tar_vm1x[24005:(24005+8000)]\n",
    "val_target_vm1y = tar_vm1y[24005:(24005+8000)]\n",
    "val_target_vm2x = tar_vm2x[24005:(24005+8000)]\n",
    "val_target_vm2y = tar_vm2y[24005:(24005+8000)]\n",
    "\n",
    "# test set\n",
    "test_input = inp[(24005+8001) : 40008 ]\n",
    "test_target_vm1x = tar_vm1x[(24005+8001) : 40008 ]\n",
    "test_target_vm1y = tar_vm1y[(24005+8001) : 40008 ]\n",
    "test_target_vm2x = tar_vm2x[(24005+8001) : 40008 ]\n",
    "test_target_vm2y = tar_vm2y[(24005+8001) : 40008 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created NN Model Instance\n"
     ]
    }
   ],
   "source": [
    "x = NNM.TFNNModels()\n",
    "model_vm1x = x.DNN_FFSeqSGD_Regulized(Learn_Rate_Schedule = False)\n",
    "model_vm1y = x.DNN_FFSeqSGD_Regulized(Learn_Rate_Schedule = False)\n",
    "model_vm2x = x.DNN_FFSeqSGD_Regulized(Learn_Rate_Schedule = False)\n",
    "model_vm2y = x.DNN_FFSeqSGD_Regulized(Learn_Rate_Schedule = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2401/2401 [==============================] - 8s 3ms/step - loss: 0.0078 - mean_squared_error: 0.0065 - val_loss: 0.0075 - val_mean_squared_error: 0.0062\n",
      "Epoch 2/5\n",
      "2401/2401 [==============================] - 7s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0059 - val_loss: 0.0076 - val_mean_squared_error: 0.0063\n",
      "Epoch 3/5\n",
      "2401/2401 [==============================] - 7s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0059 - val_loss: 0.0074 - val_mean_squared_error: 0.0061\n",
      "Epoch 4/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0059 - val_loss: 0.0074 - val_mean_squared_error: 0.0061\n",
      "Epoch 5/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0059 - val_loss: 0.0073 - val_mean_squared_error: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f29213100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vm1x.fit(train_input,train_target_vm1x,validation_data=(val_input, val_target_vm1x),\n",
    "epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_vm1x\\assets\n"
     ]
    }
   ],
   "source": [
    "model_vm1x.save('model_vm1x') # Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2401/2401 [==============================] - 7s 3ms/step - loss: 0.0877 - mean_squared_error: 0.0865 - val_loss: 0.0596 - val_mean_squared_error: 0.0584\n",
      "Epoch 2/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0830 - mean_squared_error: 0.0818 - val_loss: 0.0560 - val_mean_squared_error: 0.0548\n",
      "Epoch 3/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0823 - mean_squared_error: 0.0811 - val_loss: 0.0552 - val_mean_squared_error: 0.0540\n",
      "Epoch 4/5\n",
      "2401/2401 [==============================] - 7s 3ms/step - loss: 0.0818 - mean_squared_error: 0.0806 - val_loss: 0.0567 - val_mean_squared_error: 0.0555\n",
      "Epoch 5/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0804 - val_loss: 0.0509 - val_mean_squared_error: 0.0498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2ac4dc70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vm1y.fit(train_input,train_target_vm1y,validation_data=(val_input, val_target_vm1y),\n",
    "epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_vm1y\\assets\n"
     ]
    }
   ],
   "source": [
    "model_vm1y.save('model_vm1y') # Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2401/2401 [==============================] - 8s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0068 - val_loss: 0.0072 - val_mean_squared_error: 0.0060\n",
      "Epoch 2/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0060 - val_loss: 0.0071 - val_mean_squared_error: 0.0059\n",
      "Epoch 3/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0060 - val_loss: 0.0072 - val_mean_squared_error: 0.0060\n",
      "Epoch 4/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0059 - val_loss: 0.0070 - val_mean_squared_error: 0.0059\n",
      "Epoch 5/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0059 - val_loss: 0.0070 - val_mean_squared_error: 0.0058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f331850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vm2x.fit(train_input,train_target_vm2x,validation_data=(val_input, val_target_vm2x),\n",
    "epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_vm2x\\assets\n"
     ]
    }
   ],
   "source": [
    "model_vm2x.save('model_vm2x') # Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2401/2401 [==============================] - 7s 3ms/step - loss: 0.0884 - mean_squared_error: 0.0870 - val_loss: 0.0545 - val_mean_squared_error: 0.0532\n",
      "Epoch 2/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0840 - mean_squared_error: 0.0827 - val_loss: 0.0550 - val_mean_squared_error: 0.0537\n",
      "Epoch 3/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0829 - mean_squared_error: 0.0816 - val_loss: 0.0538 - val_mean_squared_error: 0.0525\n",
      "Epoch 4/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0820 - mean_squared_error: 0.0807 - val_loss: 0.0508 - val_mean_squared_error: 0.0495\n",
      "Epoch 5/5\n",
      "2401/2401 [==============================] - 6s 3ms/step - loss: 0.0815 - mean_squared_error: 0.0802 - val_loss: 0.0521 - val_mean_squared_error: 0.0508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f304f9370>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vm2y.fit(train_input,train_target_vm2y,validation_data=(val_input, val_target_vm2y),\n",
    "epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_vm2y\\assets\n"
     ]
    }
   ],
   "source": [
    "model_vm2y.save('model_vm2y') # Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_model1 = keras.models.load_model('model_vm1x')  # LOAD MODEL\n",
    "learned_model2 = keras.models.load_model('model_vm1y')  # LOAD MODEL\n",
    "learned_model3 = keras.models.load_model('model_vm2x')  # LOAD MODEL\n",
    "learned_model4 = keras.models.load_model('model_vm2y')  # LOAD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Eval and Eval Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model m1x\n",
      "Test loss: 0.00712989317253232\n",
      "Test mse: 0.005897347815334797\n",
      "Model m1y\n",
      "Test loss: 0.06555557250976562\n",
      "Test mse: 0.0643819272518158\n",
      "Model m2x\n",
      "Test loss: 0.006935664918273687\n",
      "Test mse: 0.005794023163616657\n",
      "Model m2y\n",
      "Test loss: 0.06754148006439209\n",
      "Test mse: 0.06623755395412445\n"
     ]
    }
   ],
   "source": [
    "score1 = learned_model1.evaluate(test_input, test_target_vm1x, verbose = 0)\n",
    "print('Model m1x')\n",
    "print('Test loss:', score1[0])\n",
    "print('Test mse:', score1[1])\n",
    "\n",
    "\n",
    "\n",
    "score2 = learned_model2.evaluate(test_input, test_target_vm1y, verbose = 0)\n",
    "print('Model m1y')\n",
    "print('Test loss:', score2[0])\n",
    "print('Test mse:', score2[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "score3 = learned_model3.evaluate(test_input, test_target_vm2x, verbose = 0)\n",
    "print('Model m2x')\n",
    "print('Test loss:', score3[0])\n",
    "print('Test mse:', score3[1])\n",
    "\n",
    "\n",
    "\n",
    "score4 = learned_model4.evaluate(test_input, test_target_vm2y, verbose = 0)\n",
    "print('Model m2y')\n",
    "print('Test loss:', score4[0])\n",
    "print('Test mse:', score4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 783ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.68055314],\n",
       "       [0.38505685],\n",
       "       [0.2766516 ],\n",
       "       [0.24085775],\n",
       "       [0.2865817 ],\n",
       "       [0.26915425],\n",
       "       [0.69272316],\n",
       "       [0.26661384],\n",
       "       [0.5509516 ],\n",
       "       [0.40648204]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_model4.predict(test_input[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy model\n",
    "dummy_model1 = x.DNN_FFSeqSGD_Regulized(Learn_Rate_Schedule = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00712989317253232\n",
      "Test mse: 0.005897347815334797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00712989317253232, 0.005897347815334797]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = learned_model1.evaluate(test_input, test_target_vm1x, verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test mse:', score[1])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11006192117929459\n",
      "Test mse: 0.10886651277542114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11006192117929459, 0.10886651277542114]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = dummy_model1.evaluate(test_input, test_target_vm1x, verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test mse:', score[1])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
